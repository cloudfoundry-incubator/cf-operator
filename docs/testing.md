# Testing

Based on upstreams documentation https://github.com/thtanaka/kubernetes/blob/master/docs/devel/testing.md we use three levels of testing: unit, integration and e2e.

Before starting, run `make tools` to install the required dependencies.

Running `make test` executes all the test suites.

We use ginkgo for testing. Every package needs a `suite_test.go` for setup. It can be generated by running `ginkgo bootstrap` in the sub folder. Rename the generated file afterwards, to stay consistent.
There is also `ginkgo generate` to create skeleton test files.

## Unit

While unit testing we:

* test classes in isolation
* pass all dependencies to the constructor, so we can inject fakes for testing
* use `counterfeiter` to generate and update fakes
* don't test private methods, tests are in a separate `_test` package
* try not to nest ginkgo contexts too deep and keep tests DRY by extracting useful helpers
* assert incoming messages produce the expected state
* assert outgoing commands happened, like a file gets written
* assert all handled error cases are triggered
* can ignore outgoing queries, which only change internal state

### Setup Ruby

Ruby gem for template rendering

    gem install bosh-template

## Integration

Integration tests formulate expectations on the interactions of several components.
They require access to a Kubernetes, preferably `minikube`.

Integration tests start our operator directly, bypassing the command line.
They do require the operator [docker image](#upload-operator-image) and the `bosh-template` Ruby gem.

The `environment` package provides helpers to start the operator, get the kubeconfig and use the clients to create objects.
In `testing` the `catalog` defines test objects.

Integration tests use a special logger, which does not log to stdout and whose messages can be accessed as a an array by calling `env.AllLogMessages()`.

When using `bin/test-integration` the integration tests are run in parallel.
Each Ginkgo test node has a separate namespace, log file and webhook server port and certificate.

The node index starts at 1 and is used as following to generate names:

		namespace: $TEST_NAMESPACE + <node_index>
		webhook port: $CF_OPERATOR_WEBHOOK_SERVICE_PORT + <node_index>
		log file: /tmp/cf-operator-tests-<node_index>.log

Integration tests use the `TEST_NAMESPACE` environment variable as a base to
calculate the namespace name. Test namespaces are deleted automatically once
the tests are completed.

### Setup Webhook Host

Extended StatefulSet requires a k8s webhook to mutate the volumes of a pod.
Kubernetes will call back to the operator for certain requests and use the
modified pod manifest, which is returned.

The cf-operator integration tests use `CF_OPERATOR_WEBHOOK_SERVICE_PORT` as a
base value to calculate the port number to listen to on
`CF_OPERATOR_WEBHOOK_SERVICE_HOST`.

The tests use a `mutatingwebhookconfiguration` to configure Kubernetes to
connect to this address. The address needs to be reachable from the cluster.

In case of minikube, the following one liner exports the IP of the host bridge
interface used by minikube:

    export CF_OPERATOR_WEBHOOK_SERVICE_HOST=$(minikube ssh -- "cat /etc/resolv.conf | grep nameserver | awk '{ printf \$2 }'")

### Mutatingwebhookconfiguration

The configuration only applies to a single namespace, by using a selector. It contains the URL of the webhooks, build from
`CF_OPERATOR_WEBHOOK_SERVICE_HOST` and the calculated port.
It also contains SSL certificates and CA, which are necessary to connect to the webhook.

The certificates and keys are written to disk, so the webhook server can use
them.  They are also cached in a k8s secret for production, but that is not
being used in integration tests, since they delete the test namespaces.

Currently only the CI scripts for integration tests clean up unused mutatingwebhookconfigurations.

		kubectl get mutatingwebhookconfiguration -oname | xargs -n 1 kubectl delete

### Upload Operator Image

Template rendering for BOSH jobs is done at deployment time by the operator
binary. Therefore the operator docker image needs to be made available to
Kubernetes cluster.

For running integration tests locally against minikube, we switch to minikubes
docker daemon, build the binary, copy it to a docker image and finally start
the tests:

    eval `minikube docker-env`
    bin/build; bin/build-nobuild-image
    bin/test-integration

The image source can be configured by these environment variables:

    DOCKER_IMAGE_ORG
    DOCKER_IMAGE_REPOSITORY
    DOCKER_IMAGE_TAG

## End-to-End

The e2e tests are meant to test acceptance scenarios. They are written from an end user perspective.
They are split into two types, 'cli' and 'kube'.

The e2e CLI test exercise different command line options and commands which don't need a running Kubernetes, like template rendering.
The CLI tests build the operator binary themselves.

The second type of e2e tests use `helm` to install the CF operator into the k8s cluster and use the files from `docs/examples` for testing.
